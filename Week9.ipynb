{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhong338/pingzhong/blob/main/Week9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a05efc8",
      "metadata": {
        "id": "2a05efc8"
      },
      "source": [
        "# FM 5222\n",
        "# Week 9\n",
        "\n",
        "\n",
        "## Agenda\n",
        "\n",
        "* AR(1)\n",
        "* Fitting AR(1)\n",
        "* AR(p)\n",
        "* Moving Avarage Models (MA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4a72488",
      "metadata": {
        "id": "c4a72488"
      },
      "source": [
        "## AR(1)\n",
        "\n",
        "Suppose we have a stationary series, but it is not White Noie.  We would seek to model the series. Of of the simplest models is the Autoregressive model with a lag of 1. The model is follows:\n",
        "\n",
        "\n",
        "$$X_{t} = (1-\\phi) \\mu + \\phi X_{t-1} +  \\epsilon_t$$\n",
        "\n",
        "where\n",
        "\n",
        "$\\phi$ is constant and $\\epsilon_t$ is white noise with mean zero. \n",
        "\n",
        "\n",
        "Note that is equivalent to (as stated in the text):\n",
        "\n",
        "$$X_{t} -  \\mu =   \\phi (X_{t-1} -\\mu) +  \\epsilon_t$$\n",
        "\n",
        "\n",
        "\n",
        "What is happening is that each value of $X_i$ is determined via a combination of it's previous value, the mean, and zero-mean white noise. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6298249",
      "metadata": {
        "id": "e6298249"
      },
      "source": [
        "We can iterate this formula as follows:\n",
        "\n",
        "\n",
        "$$X_t =(1-\\phi) \\mu + \\phi X_{t-1} +  \\epsilon_t\\\\\n",
        "= (1-\\phi) \\mu + \\phi \\left((1-\\phi) \\mu + \\phi X_{t-2} +  \\epsilon_{t-1}\\right) +  \\epsilon_t\\\\\n",
        "= (1-\\phi^2)\\mu + \\phi^2X_{t-2} + \\epsilon_t + \\phi \\epsilon_{t-1} $$\n",
        "\n",
        "Continuing on for some $h>1$, \n",
        "\n",
        "$$X_t = (1-\\phi^h)\\mu + \\phi^hX_{t-h} + \\sum_{k = 0}^{h-1}  \\phi^k \\epsilon_{t-k} $$\n",
        "\n",
        "\n",
        "We can then see that:\n",
        "\n",
        "\n",
        "$$\\mathrm{E}(X_t) = (1-\\phi^h)\\mu  + \\phi^h\\mathrm{E}(X_{t-h})$$\n",
        "\n",
        "and that (noting the epsilons are uncorrelated)\n",
        "\n",
        "$$\\mathrm{Var}(X_t) = \\phi^h \\mathrm{Var}(X_{t-h})  +  \\sum_{k = 0}^{h-1}  \\phi^{2k} \\sigma^2_{\\epsilon}$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df4e74d",
      "metadata": {
        "id": "2df4e74d"
      },
      "source": [
        "If we assume that $|\\phi| <1$, the taking the limit as $h \\to \\infty$ tells us that\n",
        "$$\\mathrm{E}(X_t) = \\mu$$\n",
        "\n",
        "\n",
        "Looking at the variance, taking the limit tells us that \n",
        "\n",
        "$$\\mathrm{Var}(X_t) = \\sigma_{\\epsilon}^2 \\sum_{k=0}^{\\infty} \\phi^{2k}\\\\\n",
        "= \\frac{\\sigma_{\\epsilon}^2}{1-\\phi^2}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ee98bf",
      "metadata": {
        "id": "40ee98bf"
      },
      "source": [
        "Next, we observe that (for $h>0$)\n",
        "\n",
        "$$\\mathrm{Cov}(X_t,X_{t-h}) = \\mathrm{Cov}\\left((1-\\phi^h)\\mu + \\phi^hX_{t-h} + \\sum_{k = 0}^{h-1}  \\phi^k \\epsilon_{t-k} ,X_{t-h}\\right) \\\\\n",
        "=  \\mathrm{Cov}\\left((1-\\phi^h)\\mu,X_{t-h}\\right) +  \\mathrm{Cov}\\left( \\phi^hX_{t-h}   ,X_{t-h}\\right) +  \\sum_{k = 0}^{h-1}\\mathrm{Cov}\\left(   \\phi^k \\epsilon_{t-k} ,X_{t-h}\\right)\\\\\n",
        "= 0 + \\phi^h \\mathrm{Var}(X_{t-h})+ \\sum_{k = 0}^{h-1}0\\\\\n",
        "= \\phi^h \\mathrm{Var}(X_{t-h})\\\\\n",
        "= \\phi^h \\frac{\\sigma_{\\epsilon}^2}{1-\\phi^2}$$\n",
        "\n",
        "\n",
        "Hence we have that there is an autocorrelationfunction and it is \n",
        "\n",
        "$$\\rho(h) = \\phi^h$$ \n",
        "\n",
        "\n",
        "Hence, if |phi| < 1, the AR(1) model is weakly stationary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239a49d2",
      "metadata": {
        "id": "239a49d2"
      },
      "source": [
        "#### $|\\phi| \\geq 1$\n",
        "\n",
        "\n",
        "If $|\\phi| \\geq 1$, then the geometric series for the variance diverges, and in particular, the series cannot be stationary.\n",
        "\n",
        "As mentioned in the text, the most basic example of this would be a random walk $\\phi = 1$.  \n",
        "\n",
        "No matter where the series starts, the variance will just grow over time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4f5e75f",
      "metadata": {
        "id": "c4f5e75f"
      },
      "source": [
        "### Convegence to Stationarity\n",
        "\n",
        "Suppose again that $|\\phi| <1$\n",
        "\n",
        "The above arguments assumed that we can just take $h \\to \\infty$.  But most series do not have \"infinite\" history. Suppose for example that there was an initial point $X_0$.  Then $$\\mathrm{E}(X_t) = (1-\\phi^t)\\mu  + \\phi^tX_0$$\n",
        "\n",
        "This will only be $\\mu$ if $X_0 = \\mu$.  However, as $t$ becomes larger, the influence of $X_0$ become smaller and essentially becomes zero. \n",
        "\n",
        "\n",
        "For the variance,\n",
        "\n",
        "\n",
        "$$\\mathrm{Var}(X_t) = \\phi^t \\mathrm{Var}(X_0)  +  \\sum_{k = 0}^{t-1}  \\phi^{2k} \\sigma^2_{\\epsilon}\\\\\n",
        "= \\phi^t \\mathrm{Var}(X_0) +\\sigma^2_{\\epsilon}\\frac{1- (\\phi^2)^{t}}{1-\\phi^2} $$\n",
        "\n",
        "\n",
        "\n",
        "And again, the influnce of the first data point goes to zero over time and the varance coverges to the same number.\n",
        "\n",
        "A similar argument works for covariance and it turns out that an AR(1) process will become stationary over time.  How fast depends on the magnitude of $\\phi$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac59760",
      "metadata": {
        "id": "bac59760"
      },
      "source": [
        "### Examples\n",
        "\n",
        "\n",
        "Let construct some AR series and see how things behave.  We will take in all cases $\\mu = 0$ and $\\sigma^2_{epsilon} = 1$   \n",
        "\n",
        "We will also take $x_0 = 10$\n",
        "\n",
        "\n",
        "#### $\\phi = .9$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels==0.13.2"
      ],
      "metadata": {
        "id": "JICjoOyFxPMI",
        "outputId": "f7ae86a7-af0b-4389-e0b0-c97b4b0cd1dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JICjoOyFxPMI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: statsmodels==0.13.2 in /usr/local/lib/python3.7/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (1.3.5)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (21.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (0.5.2)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->statsmodels==0.13.2) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->statsmodels==0.13.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->statsmodels==0.13.2) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.2->statsmodels==0.13.2) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94f3e03",
      "metadata": {
        "id": "e94f3e03"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f91482c0",
      "metadata": {
        "id": "f91482c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "T = 1000\n",
        "x0 = 10\n",
        "\n",
        "phi = .9\n",
        "\n",
        "x = np.ones(T+1)\n",
        "\n",
        "epsilons = np.random.normal(size = T)\n",
        "\n",
        "x[0] = x0\n",
        "\n",
        "for k in range(T):\n",
        "    x[k+1] = phi* x[k]   +epsilons[k]\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "\n",
        "plt.plot(x)\n",
        "\n",
        "plt.title(\"$\\\\phi =$ \"+ str(phi))\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d1fa78",
      "metadata": {
        "id": "98d1fa78"
      },
      "outputs": [],
      "source": [
        "x.var(axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59c7ded0",
      "metadata": {
        "id": "59c7ded0"
      },
      "source": [
        "#### $\\phi = .5$\n",
        "\n",
        "\n",
        "This should converge to stationary much quicker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f8d098c",
      "metadata": {
        "id": "9f8d098c"
      },
      "outputs": [],
      "source": [
        "phi = .5\n",
        "\n",
        "x = np.ones(T+1)\n",
        "\n",
        "epsilons = np.random.normal(size = T)\n",
        "\n",
        "x[0] = x0\n",
        "\n",
        "for k in range(T):\n",
        "    x[k+1] = phi* x[k]  +epsilons[k]\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "plt.plot(x)\n",
        "\n",
        "plt.title(\"$\\\\phi =$ \"+ str(phi))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8860303e",
      "metadata": {
        "id": "8860303e"
      },
      "source": [
        "#### $\\phi = -.5$\n",
        "\n",
        "Just to see that sign won't change the fact that it will converge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0d9b48c",
      "metadata": {
        "id": "f0d9b48c"
      },
      "outputs": [],
      "source": [
        "phi = -.5\n",
        "\n",
        "x = np.ones(T+1)\n",
        "\n",
        "epsilons = np.random.normal(size = T)\n",
        "\n",
        "x[0] = x0\n",
        "\n",
        "for k in range(T):\n",
        "    x[k+1] = phi* x[k]  +epsilons[k]\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "plt.plot(x)\n",
        "\n",
        "plt.title(\"$\\\\phi =$ \"+ str(phi))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a7c12d",
      "metadata": {
        "id": "b4a7c12d"
      },
      "source": [
        "#### $\\phi = 1.1$\n",
        "\n",
        "This will diverge, as we will now see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cffdd47",
      "metadata": {
        "id": "6cffdd47"
      },
      "outputs": [],
      "source": [
        "phi = 1.1\n",
        "\n",
        "x = np.ones(T+1)\n",
        "\n",
        "epsilons = np.random.normal(size = T)\n",
        "\n",
        "x[0] = x0\n",
        "\n",
        "for k in range(T):\n",
        "    x[k+1] = phi* x[k]  +epsilons[k]\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "plt.plot(x)\n",
        "\n",
        "plt.title(\"$\\\\phi =$ \"+ str(phi))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9011ce4",
      "metadata": {
        "id": "a9011ce4"
      },
      "source": [
        "#### Variance and autocorrelations\n",
        " \n",
        " \n",
        "If our series converges to stationary, we should be able to cut off  the first (say) 100 observations and see if things behave according to theory.  Recall from above that we should have\n",
        "\n",
        "\n",
        "$$\\mathrm{Var}(X_i) =  \\frac{\\sigma_{\\epsilon}^2}{1-\\phi^2}$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\\rho(h) = \\phi^h$$\n",
        "\n",
        "\n",
        "Let see:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56bd2fc1",
      "metadata": {
        "id": "56bd2fc1"
      },
      "outputs": [],
      "source": [
        "phi = .7\n",
        "\n",
        "x = np.ones(T+1)\n",
        "\n",
        "epsilons = np.random.normal(size = T)\n",
        "\n",
        "x[0] = x0\n",
        "\n",
        "for k in range(T):\n",
        "    x[k+1] = phi* x[k]  +epsilons[k]\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "1/(1-phi**2) , x[100:].var()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba0540c",
      "metadata": {
        "id": "6ba0540c"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa import stattools\n",
        "\n",
        "h = np.arange(500)+1\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "plt.plot(h,stattools.acf(x[100:], nlags=500)[1:], label = \"ACF\")\n",
        "\n",
        "plt.plot(h,phi**h, label = \"ACF_theory\")\n",
        "\n",
        "plt.title(\"ACF for AR(1)\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b23da6bc",
      "metadata": {
        "id": "b23da6bc"
      },
      "source": [
        "## Fitting AR(1)\n",
        "\n",
        "Now let's suppose we had a time series that we suspect might be AR(1).  How would we estimate the parameters?\n",
        "\n",
        "\n",
        "Let's take an MLE approach.    \n",
        "\n",
        "Supposse the process for the White Nose $\\epsilon$ has pdf $g(x)$.\n",
        "\n",
        "\n",
        "We know that $X_t = (1-\\phi)\\mu + \\phi X_{t-1} + \\epsilon_t$\n",
        "\n",
        "Hence, the PDF for $X_t$ conditioned on $X_{t-1}$ is the same at that of $\\epsilon_t$ but with mean $(1-\\phi)\\mu + \\phi X_{t-1}$.  This means that\n",
        "\n",
        "$$f_{X_t|X_{t-1}}(x_t; x_{t-1}) = g\\left(x_t - \\left((1-\\phi)\\mu + \\phi x_{t-1})\\right)\\right)$$ \n",
        "\n",
        "\n",
        "\n",
        "The *joint* PDF for the sequence $(x_0,x_1, x_2, ..., x_t)$ is therefore\n",
        "\n",
        "$$f_{(X_0,X_1,...X_t)}(x_0,x_1,...x_t) = f_{X_0}(x_0)\\times f_{X_1|X_0}(x_1;x_0) \\times \\cdots \\times f_{X_t|X_{t-1}}(x_t; x_{t-1})\\\\\n",
        "= f_{X_0}(x_0)\\times g\\left(x_1 - \\left((1-\\phi)\\mu + \\phi x_0)\\right)\\right) \\times \\cdots  \\times g\\left(x_t - \\left((1-\\phi)\\mu + \\phi x_{t-1})\\right)\\right) $$\n",
        "\n",
        "\n",
        "As per usual, we change the product to a sum and seek to maximize\n",
        "\n",
        "$$\\ln(f_{X_0}(x_0)) + \\sum_{k=1}^t \\ln\\left(  g\\left(x_k - \\left((1-\\phi)\\mu + \\phi x_{k-1})\\right)\\right)\\right)$$\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc275648",
      "metadata": {
        "id": "fc275648"
      },
      "source": [
        "If we know (or assume) the form of $g$, we can minimize the terms in the sum. Since in general, we don't much about the distribution $X_0$, especially how it depends on our parameters, we ignore it.  This is in fact what most softwares will do.  \n",
        "\n",
        "Furthermore, they assume the White Noise term is Guassian White noise.  This makes the estimation relatively straight forward.\n",
        "\n",
        "\n",
        "If however, we assume not only Guassian White noise, but that the series waas already stationary at $X_0$, then it follows that $X_0$ is normally distributed with a mean of $\\mu$ and a variance of $\\frac{\\sigma_{\\epsilon}^2}{1-\\phi^2}$.  Then we can include this term in the sum above and optimize that.\n",
        "\n",
        "In practice, it typically makes almost no difference.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f8cc760",
      "metadata": {
        "id": "9f8cc760"
      },
      "source": [
        "### Linear Regression\n",
        "\n",
        "If you are astute, you will regognize that in the case that we take $x_0$ are given (not assuming already stationary) and that the noise Guassian, then the MLE problem will be least-square regression pretty much the same as linear regression.\n",
        "\n",
        "Indeed, we can think of the model $$X_t = (1-\\phi)\\mu + \\phi X_{t-1} + \\epsilon_t$$\n",
        "\n",
        "just like a linear model where\n",
        "\n",
        "* The vector $x = (x_0,x_1,x_2, ..., x_{T-1})^T$ is the feature\n",
        "* The vector $y= (x_1,x_2, ..., x_T)^T$, is response\n",
        "* (1-\\phi)\\mu is the intercept\n",
        "* $\\phi$ is the regression coefficient.\n",
        "\n",
        "We could make the \"data matrix\"\n",
        "\n",
        "$$X = \\begin{bmatrix}  1 & x_0 \\\\1 & x_1\\\\ \\vdots  & \\vdots \\\\ 1 & x_{T-1} \\\\ \\end{bmatrix}$$\n",
        "\n",
        "And regress just like we did before.  In fact, let's make some fake AR(1) data and fit the parameters this way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3684cad0",
      "metadata": {
        "id": "3684cad0"
      },
      "outputs": [],
      "source": [
        "T = 1000\n",
        "phi = .5\n",
        "sigma= .2\n",
        "mu = 10\n",
        "\n",
        "x0 = 7\n",
        "\n",
        "x= np.zeros(T+1)\n",
        "\n",
        "x[0] = x0\n",
        "\n",
        "epsilons = np.random.normal(size = T, scale = sigma)\n",
        "\n",
        "\n",
        "for k in range(T):\n",
        "    x[k+1] = (1-phi)*mu + phi* x[k] + epsilons[k]\n",
        "    \n",
        "\n",
        "X = np.ones([T,2])\n",
        "\n",
        "X[:,1] = x[:-1]\n",
        "y = x[1:]\n",
        "\n",
        "\n",
        "bhat = np.linalg.pinv(X)@y\n",
        "\n",
        "print(\"phi hat is\", bhat[1])\n",
        "print(\"mu hat is \", bhat[0]/(1- bhat[1]))\n",
        "\n",
        "print(\"bhat is \", bhat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84bcd9ed",
      "metadata": {
        "id": "84bcd9ed"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c0e6245",
      "metadata": {
        "id": "2c0e6245"
      },
      "source": [
        "Naturally, there are packages tailored to AR that will do this for us (and give us diagnostics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c32f5c",
      "metadata": {
        "id": "11c32f5c"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "\n",
        "mod = AutoReg(x , 1)\n",
        "res = mod.fit()\n",
        "print(res.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb049859",
      "metadata": {
        "id": "eb049859"
      },
      "source": [
        "Better yet, this will also give us some nice diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "382eeb10",
      "metadata": {
        "id": "382eeb10"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 9))\n",
        "fig = res.plot_diagnostics(fig=fig, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f712eaea",
      "metadata": {
        "id": "f712eaea"
      },
      "source": [
        "### Some examples\n",
        "\n",
        "Let's grab some time series and attempt to AR(1) fit them.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6795f7",
      "metadata": {
        "id": "bd6795f7"
      },
      "outputs": [],
      "source": [
        "import pandas_datareader.data as dr\n",
        "\n",
        "edata = CPI = dr.DataReader(['WM2NS','UNRATE','CPIAUCSL','GDPC1'], 'fred', \"2010-01-01\", \"2019-12-31\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feb70620",
      "metadata": {
        "id": "feb70620"
      },
      "source": [
        "Let fit the change in unemployment rate to an AR(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "793fe5ed",
      "metadata": {
        "id": "793fe5ed"
      },
      "outputs": [],
      "source": [
        "unemp = (edata.UNRATE).dropna()\n",
        "\n",
        "unempchange = unemp.diff().dropna()\n",
        "\n",
        "\n",
        "plt.figure(figsize= (15,10))\n",
        "\n",
        "plt.plot(unempchange)\n",
        "\n",
        "plt.title(\"Change in unemployment\")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d9aa17",
      "metadata": {
        "id": "e4d9aa17"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d24647",
      "metadata": {
        "id": "08d24647"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0104f104",
      "metadata": {
        "id": "0104f104"
      },
      "outputs": [],
      "source": [
        "mod = AutoReg(unempchange , 1)\n",
        "res = mod.fit()\n",
        "print(res.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d5f2ddb",
      "metadata": {
        "id": "0d5f2ddb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2ce767f",
      "metadata": {
        "id": "e2ce767f"
      },
      "source": [
        "Conveniently, we can also get some quick diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca99f813",
      "metadata": {
        "id": "ca99f813"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 9))\n",
        "fig = res.plot_diagnostics(fig=fig, lags=30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6da8e7f",
      "metadata": {
        "id": "a6da8e7f"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.diagnostic import acorr_ljungbox as lbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ab8c3f",
      "metadata": {
        "id": "71ab8c3f"
      },
      "outputs": [],
      "source": [
        "lbox(res.resid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3952c251",
      "metadata": {
        "id": "3952c251"
      },
      "source": [
        "Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34be0d87",
      "metadata": {
        "id": "34be0d87"
      },
      "source": [
        "Now let's try inflation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a861be5",
      "metadata": {
        "id": "5a861be5"
      },
      "outputs": [],
      "source": [
        "cpi = edata.CPIAUCSL.dropna()\n",
        "\n",
        "\n",
        "\n",
        "ifl_monthly= (cpi.diff()/cpi.shift(1)).dropna()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1fc37f9",
      "metadata": {
        "id": "f1fc37f9"
      },
      "outputs": [],
      "source": [
        "mod = AutoReg(ifl_monthly , 1)\n",
        "res = mod.fit()\n",
        "print(res.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3652492d",
      "metadata": {
        "id": "3652492d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6353eaf",
      "metadata": {
        "id": "c6353eaf"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 9))\n",
        "fig = res.plot_diagnostics(fig=fig, lags=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10399ef1",
      "metadata": {
        "id": "10399ef1"
      },
      "outputs": [],
      "source": [
        "lbox(res.resid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f312ac9",
      "metadata": {
        "id": "4f312ac9"
      },
      "source": [
        "This also seems somewhat reasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7050d69",
      "metadata": {
        "id": "e7050d69"
      },
      "source": [
        "Finally, we try M2 Change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "731f1945",
      "metadata": {
        "id": "731f1945"
      },
      "outputs": [],
      "source": [
        "m2 = (edata.WM2NS).dropna()\n",
        "\n",
        "m2change = m2.diff().dropna()\n",
        "\n",
        "\n",
        "mod = AutoReg(m2change , 1)\n",
        "res = mod.fit()\n",
        "print(res.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7915bdf3",
      "metadata": {
        "id": "7915bdf3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7475e4",
      "metadata": {
        "id": "ee7475e4"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 9))\n",
        "fig = res.plot_diagnostics(fig=fig, lags=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0b0890",
      "metadata": {
        "id": "8c0b0890"
      },
      "outputs": [],
      "source": [
        "lbox(res.resid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1087f3d",
      "metadata": {
        "id": "f1087f3d"
      },
      "source": [
        "For this exampe, AR(1) doesn't cut it.   \n",
        "\n",
        "## AR(p)\n",
        "\n",
        "\n",
        "A generaliztion of AR(1) is AR(p) where of course $p \\geq 1$\n",
        "\n",
        "\n",
        "The form is:\n",
        "\n",
        "$$X_t = \\phi_0 + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\cdots \\phi_p X_{t-p} + \\epsilon_t $$\n",
        "\n",
        "\n",
        "In this formulation, the stationary mean will be \n",
        "\n",
        "$$\\mu = \\frac{\\phi_0}{1-(\\phi_1 +\\phi_2 + \\cdots + \\phi_p) }$$\n",
        "\n",
        "\n",
        "The fit for this model can also be done via linear regression.  \n",
        "\n",
        "Let's cook another fake set with $p =3$, solve it via linear regression and compare to the statsmodels' AutoReg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4048a977",
      "metadata": {
        "id": "4048a977"
      },
      "outputs": [],
      "source": [
        "T = 1000\n",
        "phi = np.array([.3,-.3,.5])\n",
        "sigma= .2\n",
        "mu = 10\n",
        "\n",
        "phi0 = mu*(1 - np.sum(phi))\n",
        "\n",
        "x0 = 15\n",
        "x1 = 13\n",
        "x2 = 11\n",
        "\n",
        "x= np.zeros(T+1)\n",
        "\n",
        "x[0:3] = np.array([x0,x1,x2])\n",
        "\n",
        "\n",
        "epsilons = np.random.normal(size = T, scale = sigma)\n",
        "\n",
        "\n",
        "for k in range(T-2):\n",
        "    x[k+3] = phi0 + phi[0]* x[k+2] +  phi[1]* x[k+1] +  phi[2]* x[k] + epsilons[k]\n",
        "    \n",
        "\n",
        "X = np.ones([T-2,4])\n",
        "\n",
        "X[:,1] = x[2:-1]\n",
        "X[:,2] = x[1:-2]\n",
        "X[:,3] = x[:-3]\n",
        "\n",
        "\n",
        "\n",
        "y = x[3:]\n",
        "\n",
        "\n",
        "bhat = np.linalg.pinv(X)@y\n",
        "\n",
        "\n",
        "print(\"mu hat is \", bhat[0]/(1- bhat[1:].sum()))\n",
        "\n",
        "print(\"bhat is \", bhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46f866a8",
      "metadata": {
        "id": "46f866a8"
      },
      "outputs": [],
      "source": [
        "\n",
        "mod = AutoReg(x , 3)\n",
        "res = mod.fit()\n",
        "print(res.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5acf4257",
      "metadata": {
        "id": "5acf4257"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 9))\n",
        "fig = res.plot_diagnostics(fig=fig, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f45a5b",
      "metadata": {
        "id": "10f45a5b"
      },
      "source": [
        "What happens if you mispecify $p$?  Let's try it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2157822",
      "metadata": {
        "id": "a2157822"
      },
      "outputs": [],
      "source": [
        "mod = AutoReg(x , 1)\n",
        "res = mod.fit()\n",
        "print(res.summary())\n",
        "fig = plt.figure(figsize=(16, 9))\n",
        "fig = res.plot_diagnostics(fig=fig, lags=30)\n",
        "      \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18cdfdac",
      "metadata": {
        "id": "18cdfdac"
      },
      "outputs": [],
      "source": [
        "mod = AutoReg(x , 5)\n",
        "res = mod.fit()\n",
        "print(res.summary())\n",
        "fig = plt.figure(figsize=(16, 9))\n",
        "fig = res.plot_diagnostics(fig=fig, lags=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "951a23c4",
      "metadata": {
        "id": "951a23c4"
      },
      "source": [
        "## Moving Average models\n",
        "\n",
        "Another common clas of time-series models that are relatively simple are Moving Average models.\n",
        "\n",
        "The concept is not that the previous values of $X_t$ are influencing the next element of the series, but rather the innovations themeselves (the innovations refer to the white noise terms). \n",
        "\n",
        "Imagine first the case where $X_t = \\mu + \\epsilon_t$\n",
        "\n",
        "In this case, the series is just randome noise scattered about the mean $\\mu$.  It will have no autocorrelation and  we might not even think of it as a time series.    \n",
        "\n",
        "### MA(1)\n",
        "\n",
        "In the MA(1) model, we change this to\n",
        "\n",
        "$$X_t = \\mu + \\epsilon_t + \\theta \\epsilon_{t-1}$$\n",
        "\n",
        "\n",
        "This means that the previous innovation \"hangs around\" a bit.  But the ones before that has no influence at all. \n",
        "\n",
        "\n",
        "We can do some staight-forward calculations to see that:\n",
        "\n",
        "$$\\mathrm{E}(X_t) = \\mu$$\n",
        "\n",
        "$$\\mathrm{Var}(X_t) = \\sigma^2_{\\epsilon}(1 + \\theta^2)$$\n",
        "\n",
        "\n",
        "$$\\mathrm{Cov}(X_t,X_{t-1}) = \\mathrm{Cov}(\\mu + \\epsilon_t + \\theta \\epsilon_{t-1},\\mu + \\epsilon_{t-1} + \\theta \\epsilon_{t-2})\\\\\n",
        "=\\mathrm{Cov}(\\epsilon_t, \\epsilon_{t-1} + \\theta \\epsilon_{t-2}) + \\mathrm{Cov}(\\theta \\epsilon_{t-1}, \\epsilon_{t-1} + \\theta \\epsilon_{t-2})\\\\\n",
        "= \\theta \\sigma_{\\epsilon}^2$$\n",
        "\n",
        "\n",
        "and for $j>1$\n",
        "\n",
        "$$\\mathrm{Cov}(X_t,X_{t-j})  = 0$$\n",
        "\n",
        "Hence the ACF will be\n",
        "\n",
        "$$\\rho(h) = \\begin{cases}\\frac{\\theta}{1+ \\theta^2},& h = 1 \\\\ 0 ,& h>1\\end{cases}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### MA(q)\n",
        "\n",
        "This generalizes nicely to \n",
        "\n",
        "$$X_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} +\\theta_2 \\epsilon_{t-2}+ \\cdots + \\theta_p \\epsilon_{t-q} $$\n",
        "\n",
        "\n",
        "We can get similar formulas as above (though they are messier).  The key thing to note is that  for MA(q), the ACF\n",
        "\n",
        "$$\\rho(h) = 0$$ whenever $h > q$.  \n",
        "\n",
        "\n",
        "This is different that AR(p) where the ACF does not technically ever hit zero. \n",
        "\n",
        "A side conclusion is that if we see the ACF go to zero after $q$ lags, it suggests that MA(q) *might* be appropriate.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f90c3eb",
      "metadata": {
        "id": "2f90c3eb"
      },
      "source": [
        "### Estimation of MA(q)\n",
        "\n",
        "The general approach is to perform MLE or something like it.  However, it does not reduce to a simple linear regression - unlike the AR(p) case.  This is because we cannot directly observe the values $\\epsilon_t$.  Fortunately, statistical software can do this numerically.  Let's generate some fake data a fit it using statsmodels.\n",
        "\n",
        "We will do MA(2) with \n",
        "\n",
        "\n",
        "$\\mu = 5$\n",
        "$\\sigma_{\\epsilon} = 1$\n",
        "$\\theta_1 = .7$\n",
        "$\\theta_2 = .4$\n",
        "\n",
        "\n",
        "We will define White Noise back to the index $-2$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e24add09",
      "metadata": {
        "id": "e24add09"
      },
      "outputs": [],
      "source": [
        "T = 1000\n",
        "mu = 5\n",
        "sigma = 1\n",
        "theta1 = .7\n",
        "theta2 = .5\n",
        "\n",
        "x = np.zeros(T)\n",
        "\n",
        "epsilons = np.random.normal(size = T+2, scale = sigma)\n",
        "\n",
        "x = mu + epsilons[2:] + theta1*epsilons[1:-1] +  theta2*epsilons[:-2]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d38a83b",
      "metadata": {
        "id": "4d38a83b"
      },
      "source": [
        "Before we fit, lets look at the ACF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb89a4d1",
      "metadata": {
        "id": "bb89a4d1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "ma = pd.plotting.autocorrelation_plot(x)\n",
        " \n",
        "# plotting the Curve\n",
        "ma.plot()\n",
        "\n",
        "plt.xlim(0,10)\n",
        "\n",
        "plt.title(\"Autocorrelation of MA(2)\")\n",
        " \n",
        "# Display\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199bcf9d",
      "metadata": {
        "id": "199bcf9d"
      },
      "source": [
        "Now let's use the software to fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9de9c0e",
      "metadata": {
        "id": "c9de9c0e"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "\n",
        "ma_mod = ARIMA(x, order=(0, 0, 2))\n",
        "ma_res = ma_mod.fit()\n",
        "\n",
        "print(ma_res.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41dace00",
      "metadata": {
        "id": "41dace00"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 9))\n",
        "fig = ma_res.plot_diagnostics(fig=fig, lags=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "015405e2",
      "metadata": {
        "id": "015405e2"
      },
      "source": [
        "## ARMA(p,q)\n",
        "\n",
        "Natuarlly, these kinds of models can be mixed together, and are called ARMA(p,q)\n",
        "\n",
        "The specification is\n",
        "\n",
        "$$X_t = \\phi_0 + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\cdots \\phi_p X_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} +\\theta_2 \\epsilon_{t-2}+ \\cdots + \\theta_p \\epsilon_{t-q}  $$\n",
        "\n",
        "As before, we will need software to fit."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f97263b",
      "metadata": {
        "id": "2f97263b"
      },
      "source": [
        "### Order selection\n",
        "\n",
        "Of course, the obvious question that is priot to fitting is, \"What should $p$ and $q$ be?\".\n",
        "\n",
        "In some cases, you may have domain knowledge that guides your choice.  But in others, one can choose the model order using AIC or BIC.   And fortunately, there is software to do that for you. Lete make a fake data set with $p =2$ and $q= 1$ and fit with software.\n",
        "\n",
        "\n",
        "We will just specify $x_0$ and $x_1$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c0640c",
      "metadata": {
        "id": "66c0640c"
      },
      "outputs": [],
      "source": [
        "T = 1000\n",
        "sigma =1\n",
        "mu = 10\n",
        "phi1 = .5\n",
        "phi2 = .2\n",
        "phi0 = mu*(1-phi1 -phi2)\n",
        "\n",
        "theta = .7\n",
        "\n",
        "epsilons = np.random.normal(size = T, scale =sigma)\n",
        "\n",
        "x = np.ones(T)\n",
        "\n",
        "x[0] = 11\n",
        "x[1] = 9\n",
        "\n",
        "\n",
        "for k in np.arange(2,T):\n",
        "    \n",
        "    x[k] = phi0 + phi1*x[k-1] + phi2*x[k-2] + epsilons[k] + theta*epsilons[k-1] \n",
        "    \n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba52839",
      "metadata": {
        "id": "3ba52839"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "res = sm.tsa.arma_order_select_ic(x, ic=[\"aic\", \"bic\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f58e6450",
      "metadata": {
        "id": "f58e6450"
      },
      "outputs": [],
      "source": [
        "res.aic_min_order, res.bic_min_order"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bb4ddf",
      "metadata": {
        "id": "f1bb4ddf"
      },
      "source": [
        "Let's circle back and try this with M2 Change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd170328",
      "metadata": {
        "id": "bd170328"
      },
      "outputs": [],
      "source": [
        "res = sm.tsa.arma_order_select_ic(m2change, ic=[\"aic\", \"bic\"])\n",
        "\n",
        "\n",
        "res.aic_min_order, res.bic_min_order\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "715f87a6",
      "metadata": {
        "id": "715f87a6"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Grab some some time series of your favorite stock.  See if you can model log-return and dialy volume.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P_zXnkrYx5od"
      },
      "id": "P_zXnkrYx5od",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Week9.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}